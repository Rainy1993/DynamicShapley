{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Efficiency - Add multiple points\n",
    "\n",
    "| comparable algo list |\n",
    "| - |\n",
    "| pivot |\n",
    "| delta |\n",
    "| Monte Carlo |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "\n",
    "import dynashap\n",
    "\n",
    "from examples.data_utils import (\n",
    "    load_npy, save_npy, preprocess_data, variance, normalize\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = svm.SVC(decision_function_shape='ovo')\n",
    "\n",
    "# size_choices = [10, 100, 1000, 10000]\n",
    "size_choices = [10, 100, 200]\n",
    "m_choices = [10, 15, 18, 20, 22, 25, 28, 30]\n",
    "stone_m = 100\n",
    "\n",
    "for size in size_choices:\n",
    "    x_train, y_train, x_test, y_test, \\\n",
    "    columns_name = preprocess_data(\n",
    "        't_train_' + str(size) + 'p.csv',\n",
    "        't_test_' + str(size) + 'p.csv')\n",
    "\n",
    "    # process data\n",
    "    x_train_ = x_train[:-2]\n",
    "    y_train_ = y_train[:-2]\n",
    "\n",
    "    # for add\n",
    "    add_points_x = x_train[-2:, :]\n",
    "    add_points_y = y_train[-2:]\n",
    "\n",
    "    x_test_ = x_test\n",
    "    y_test_ = y_test\n",
    "\n",
    "    # get a init sv\n",
    "    init_sv = dynashap.mc_shap(x_train_, y_train_, x_test_, y_test_, model,\n",
    "                               stone_m * len(y_train_), proc_num=2)\n",
    "    save_npy('am_init_mc_plus_size' + str(size) + '.npy', init_sv)\n",
    "\n",
    "    # set a stone\n",
    "    mc_plus = dynashap.mc_shap(x_train, y_train, x_test_, y_test_, model,\n",
    "                               stone_m * len(y_train), proc_num=2)\n",
    "    save_npy('am_mc_plus_size' + str(size) + '.npy', mc_plus)\n",
    "\n",
    "    # mc -> 比较标准\n",
    "    mc = dynashap.mc_shap(x_train, y_train, x_test_, y_test_, model, mc_stone * len(y_train))\n",
    "    save_npy('am_mc'+ str(size) + 'm' + str(mc_stone) + '.npy', mc)\n",
    "\n",
    "    # half 需要提前算好的lsv\n",
    "    half_shap = dynashap.PivotShap(x_train_, y_train_, x_test_, y_test_, model,\n",
    "                                  None)\n",
    "    lsv = half_shap.prepare(m=len(y_train_)*stone_m)\n",
    "    save_npy('am_half_lsv_size' + str(size) + '.npy', lsv)\n",
    "\n",
    "    # # walk the m choices\n",
    "    for m in m_choices:\n",
    "        # delta\n",
    "        delta_shap = dynashap.DeltaShap(x_train_, y_train_, x_test_, y_test_, model,\n",
    "                                        init_sv)\n",
    "\n",
    "        m_delta_sv = delta_shap.add_single_point(add_points_x[0],\n",
    "                                                 add_points_y[0],\n",
    "                                                 m=(len(y_train_)+1)*m)\n",
    "\n",
    "        m_delta_sv = dynashap.utils.eval_utility(x_train[:-1], y_train[-1], x_test_, y_test_, model)/ \\\n",
    "                     (np.sum(m_delta_sv)* m_delta_sv)\n",
    "\n",
    "        n_delta_shap = dynashap.DeltaShap(x_train[:-1], y_train[-1], x_test_, y_test_,\n",
    "                                          model, m_delta_sv)\n",
    "\n",
    "        delta_sv = n_delta_shap.add_single_point(add_points_x[1],\n",
    "                                                 add_points_y[1],\n",
    "                                                 m=(len(y_train_)+2)*m)\n",
    "        save_npy('am_delta_size' + str(size) +'m' + str(m) + '.npy', delta_sv)\n",
    "\n",
    "        # half\n",
    "        half_shap = dynashap.PivotShap(x_train_, y_train_, x_test_, y_test_, model,\n",
    "                                      None)\n",
    "        half_shap.left_sv = lsv\n",
    "        _ = half_shap.add_single_point(add_points_x[0], add_points_y[0],\n",
    "                                       (len(y_train_)+1)*m,\n",
    "                                       {'flag_lsv': True})\n",
    "        half_shap.x_train = x_train[:-1,:]\n",
    "        half_shap.y_train = y_train[:-1]\n",
    "        half_sv = half_shap.add_single_point(add_points_x[1], add_points_y[1],\n",
    "                                       (len(y_train_)+2)*m,\n",
    "                                       {'flag_lsv': True})\n",
    "        save_npy('am_half_size' + str(size) +'m' + str(m) + '.npy', half_sv)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}